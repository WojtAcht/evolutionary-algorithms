{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 1 - Hypotheses Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Required dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First let us install what is needed - jmetalpy and scikit-posthocs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install jmetalpy\n",
        "%pip install scikit-posthocs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scikit_posthocs as sp\n",
        "from scipy import stats\n",
        "from jmetal.core.observer import Observer\n",
        "import logging\n",
        "from jmetal.problem.singleobjective.unconstrained import Sphere\n",
        "from jmetal.core.solution import FloatSolution\n",
        "from jmetal.algorithm.singleobjective.local_search import LocalSearch\n",
        "from jmetal.operator import SimpleRandomMutation\n",
        "from jmetal.util.termination_criterion import StoppingByEvaluations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hypotheses Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Basic example - tossing a coin."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "HEADS = 0\n",
        "TAILS = 1\n",
        "\n",
        "COIN_VALUES = [HEADS, TAILS]\n",
        "\n",
        "\n",
        "def get_coin_tosses(number_of_tosses: int, probabilities: list[int] = [0.5, 0.5]) -> np.ndarray:\n",
        "    return np.random.choice(COIN_VALUES, size=number_of_tosses, replace=True, p=probabilities)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Implement a function to `run_experiment`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_experiment(number_of_trials: int, number_of_tosses: int, probabilities: list[int] = [0.5, 0.5]) -> list[float]:\n",
        "    \"\"\"The run_experiment function is designed to simulate a coin tossing experiment\n",
        "    with a specified number of trials (number_of_trials) and a given number of coin tosses per trial (number_of_tosses).\n",
        "    It allows you to set the probabilities of getting tails and heads for the coin, with the default values of 0.5 for both sides (representing a fair coin).\n",
        "    In each trial, it calculates the mean (probability of TAILS) of coin_tosses and returns a list of means.\"\"\"\n",
        "    # TODO: Implement me!\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "def plot_experiment(tails_probabilities: list[float]) -> None:\n",
        "    plt.hist(tails_probabilities, density=True)\n",
        "    plt.xlabel(\"Mean probability\")\n",
        "    plt.ylabel(\"Density\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot results of the experiment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tails_probabilities = run_experiment(number_of_trials=10000, number_of_tosses=1000, probabilities=[0.5, 0.5])\n",
        "plot_experiment(tails_probabilities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tails_probabilities = run_experiment(number_of_trials=10000, number_of_tosses=1000, probabilities=[0.2, 0.8])\n",
        "plot_experiment(tails_probabilities)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Kruskal-Wallis test\n",
        "We will implement a simplified version for 2 samples. <br>\n",
        "#### Method:\n",
        "1. Rank all data from all groups together; i.e., rank the data from 1 to N ignoring group membership. Assign any tied values the average of the ranks they would have received had they not been tied.\n",
        "2. Calculate the test statistic:\n",
        "$$ H = \\frac{12}{N (N+1)}(n_1 \\cdot \\overline{r_1}^2 + n_2 \\cdot \\overline{r_2}^2) - 3(N+1) $$\n",
        "Where:\n",
        "- $n_1$ is the number of observations in $sample_1$ and $n_2$ is the number of observations in $sample_2$,\n",
        "- $N = n_1 + n_2$ is the total number of observations across all samples,\n",
        "- $\\overline{r_1}$ is the average rank of all observations in $sample_1$.\n",
        "3. Finally, the decision to reject or not the null hypothesis is made by comparing H to a critical value $H_{c}$ obtained from a table or a software for a given significance or alpha level. If  H is bigger than $H_{c}$, the null hypothesis is rejected. If possible (no ties, sample not too big) one should compare H to the critical value obtained from the exact distribution of H. Otherwise, the distribution of H can be approximated by a chi-squared distribution with 1 degree of freedom (in general $g-1$ degrees of freedom where $g$ is the number of samples). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Source: https://en.wikipedia.org/wiki/Kruskal%E2%80%93Wallis_one-way_analysis_of_variance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def kruskal_wallis(sample1: np.ndarray, sample2: np.ndarray) -> tuple[float, float]:\n",
        "    # TODO: Implement me!\n",
        "    # Use rankdata function from scipy for convenience\n",
        "    all_samples = np.concatenate([sample1, sample2])\n",
        "    ranks = stats.rankdata(all_samples, method=\"min\")\n",
        "    # H = ...\n",
        "    # p_value = stats.chi2.sf(H, 1)\n",
        "    # return H, p_value\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Null and alternative hypotheses.\n",
        "The null hypothesis ($H_0$) often represents either a skeptical perspective or a claim of “no difference” to be tested.\n",
        "The alternative hypothesis ($H_A$) represents an alternative claim under consideration and is often represented by a range of possible values for the value of interest."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### P-value\n",
        "The p-value is the probability of observing data at least as favorable to the alternative hypothesis as our current dataset, if the null hypothesis were true. We typically use a summary statistic of the data, such as a difference in proportions, to help compute the p-value and evaluate the hypotheses. This summary value that is used to compute the p-value is often called the test statistic."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Source: https://openintro-ims.netlify.app/foundations-randomization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test if your implementation is correct:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample1 = np.array([1, 2, 3])\n",
        "sample2 = np.array([4, 6, 5])\n",
        "scipy_result = stats.kruskal(sample1, sample2)\n",
        "custom_result = kruskal_wallis(sample1, sample2)\n",
        "\n",
        "assert np.isclose(scipy_result.statistic, custom_result[0])\n",
        "assert np.isclose(scipy_result.pvalue, custom_result[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate a sample for a fair coin and for a biased coin. Then check if we can detect the biased coin using Kruskal-Wallis test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "number_of_trials = 1000\n",
        "number_of_tosses = 100\n",
        "fair_coin_probabilities = [0.5, 0.5]\n",
        "biased_coin_probabilities = [0.49, 0.51] \n",
        "fair_coin_means = run_experiment(\n",
        "    number_of_trials=number_of_trials, number_of_tosses=number_of_tosses, probabilities=fair_coin_probabilities\n",
        ")\n",
        "biased_coin_means = run_experiment(\n",
        "    number_of_trials=number_of_trials, number_of_tosses=number_of_tosses, probabilities=biased_coin_probabilities\n",
        ")\n",
        "kruskal_wallis(fair_coin_means, biased_coin_means)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Q: How to decide if a coin is biased using `pvalue`?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fun fact"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fair coins tend to land on the same side they started: Evidence from 350,757 flips."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Source: https://arxiv.org/abs/2310.04153"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Key takeaways:\n",
        "- statistical testing is just another tool in your toolkit,\n",
        "- we use statistical tests to check if we can reject a hypothesis - e.g. to check if samples originate from the same distribution,\n",
        "- there are many statistical tests already implemented in scipy,\n",
        "- many ML/statistical libraries provide statistical tests out of the box (e.g. `statsmodels.regression.linear_model.OLS`) - it's crucial to understand what are the p-values,\n",
        "- try to use statistical tests for your master thesis (e.g. to check if the results of one ML algorithm are better than the baseline). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## jMetalPy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbqJNRYgKhl-"
      },
      "source": [
        "During this lab we will take a look at the jMetalPy platform, run the first simple heuristic algorithm (local search) and play with different methods of visualization and testing statistical significance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "jMetalPy provides implementation for many optimization problems - right now we will focus on `Sphere`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Alt text](https://www.sfu.ca/~ssurjano/spheref.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Source: https://www.sfu.ca/~ssurjano/spheref.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`Sphere` is defined by a formula:\n",
        "$$ f(x) = \\sum_{i=1}^{d} x_i^2 $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Global Minimum:\n",
        "$ f(x^*) = 0 $, at $x^* = (0, ..., 0)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can check it for $d=2$ and $x = [1, 2]$. The result should be equal to:\n",
        "$$ f(x) = 1^2 + 2^2 = 5$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "logger = logging.getLogger('jmetal.core.algorithm')\n",
        "logger.setLevel(logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "problem = Sphere(2)\n",
        "solution = FloatSolution(problem.lower_bound, problem.upper_bound, problem.number_of_objectives())\n",
        "solution.variables = [1.0, 2.0]\n",
        "assert problem.evaluate(solution).objectives[0] == 5.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`LocalSearch` works like this:\n",
        "- start with 1 random point from domain (sampled with uniform distribution) called `solution`,\n",
        "- for each step run mutation for the `solution`,\n",
        "- if fitness value after running mutation is better than before replace `solution` with mutated `solution`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqbgBBvEK2Y0",
        "outputId": "527e7660-454d-4f65-f760-d180ff00bded"
      },
      "outputs": [],
      "source": [
        "# Problem definition and Local Search parameters:\n",
        "PROBLEM = Sphere(10)\n",
        "MAX_EVALUATIONS = 100\n",
        "MUTATION = SimpleRandomMutation(1.0 / PROBLEM.number_of_variables())\n",
        "TERMINATION_CRITERION = StoppingByEvaluations(max_evaluations=MAX_EVALUATIONS)\n",
        "\n",
        "\n",
        "def get_local_search(max_evaluations: int = MAX_EVALUATIONS) -> LocalSearch:\n",
        "    return LocalSearch(\n",
        "        problem=PROBLEM,\n",
        "        mutation=MUTATION,\n",
        "        termination_criterion=StoppingByEvaluations(max_evaluations=max_evaluations),\n",
        "    )\n",
        "\n",
        "\n",
        "algorithm = get_local_search()\n",
        "algorithm.run()\n",
        "result = algorithm.get_result()\n",
        "\n",
        "print(\"Algorithm: \" + algorithm.get_name())\n",
        "print(\"Problem: \" + problem.name())\n",
        "print(\"Solution: \" + str(result.variables))\n",
        "print(\"Fitness:  \" + str(result.objectives[0]))\n",
        "print(\"Computing time: \" + str(algorithm.total_computing_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5BNLyBQW-uU"
      },
      "source": [
        "This is of course a heuristic algorithm, let us run it many times and show the dispersion of the outcome.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "os_wNQyJXB6-",
        "outputId": "5b6db5b8-29df-474c-dd3a-c307162314cf"
      },
      "outputs": [],
      "source": [
        "STEPS = 30\n",
        "results = []\n",
        "for _ in range(STEPS):\n",
        "  algorithm = get_local_search()\n",
        "  algorithm.run()\n",
        "  result = algorithm.get_result().objectives[0]\n",
        "  results.append(result)\n",
        "\n",
        "plt.boxplot(results)\n",
        "plt.ylabel(\"Fitness\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISV6STZ2eL9_"
      },
      "source": [
        "It would be nice to see the progress of the algorithm. First let us take a look at a toy  - a progress bar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaK6_WBneWm0",
        "outputId": "86cf0216-742a-4fba-993b-43ac5339007b"
      },
      "outputs": [],
      "source": [
        "from jmetal.util.observer import ProgressBarObserver\n",
        "\n",
        "max_evaluations = 100000\n",
        "algorithm = get_local_search(max_evaluations=max_evaluations)\n",
        "basic = ProgressBarObserver(max=max_evaluations)\n",
        "algorithm.observable.register(observer=basic)\n",
        "\n",
        "algorithm.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CkqFmxhktzb"
      },
      "source": [
        "However it would be better to take a closer look at what is happening in the algorithm - what is the value of the best fitness in every step, or at certain moments in time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "TofOOluzk0AI",
        "outputId": "a7929df5-b5ca-4a8c-f644-103c413bc28c"
      },
      "outputs": [],
      "source": [
        "class DataObserver(Observer):\n",
        "\n",
        "    def __init__(self, frequency: float = 1.0) -> None:\n",
        "        \"\"\" Show the number of evaluations, best fitness and computing time.\n",
        "        :param frequency: Display frequency. \"\"\"\n",
        "        self.display_frequency = frequency\n",
        "        self.data = []\n",
        "\n",
        "    def update(self, *args, **kwargs):\n",
        "        evaluations = kwargs['EVALUATIONS']\n",
        "        solutions = kwargs['SOLUTIONS']\n",
        "\n",
        "        if (evaluations % self.display_frequency) == 0 and solutions:\n",
        "            if type(solutions) == list:\n",
        "                fitness = solutions[0].objectives\n",
        "            else:\n",
        "                fitness = solutions.objectives\n",
        "            self.data.append(fitness[0])\n",
        "\n",
        "algorithm = get_local_search()\n",
        "dataobserver = DataObserver(frequency=1.0)\n",
        "algorithm.observable.register(observer=dataobserver)\n",
        "\n",
        "algorithm.run()\n",
        "\n",
        "print(len(dataobserver.data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(dataobserver.data)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShLMqEWPKRyH"
      },
      "source": [
        "Now let us take a proper look at the progress of the algorithm. Let us repeat it many times, and draw an appropriate box and whiskers plot for every moment in time, observing the best fitness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "Tyl7giidKYkF",
        "outputId": "965d6a37-ae26-4cae-c041-0be0435467fd"
      },
      "outputs": [],
      "source": [
        "all_data = []\n",
        "for _ in range(STEPS):\n",
        "  data = []\n",
        "  algorithm = get_local_search()\n",
        "  dataobserver = DataObserver(frequency=1.0)\n",
        "  algorithm.observable.register(observer=dataobserver)\n",
        "  algorithm.run()\n",
        "  all_data.append(dataobserver.data)\n",
        "\n",
        "numpy_array = np.array(all_data)\n",
        "transpose = numpy_array.T\n",
        "transpose_list = transpose.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(15, 10))\n",
        "ax = fig.add_subplot(111)\n",
        "bp = ax.boxplot(transpose_list)\n",
        "x_ticks = np.arange(0, MAX_EVALUATIONS, 10)\n",
        "plt.xticks(x_ticks, x_ticks)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Statistical tests\n",
        "A Kruskal-Wallis test is used for testing whether (two or more) samples originate from the same distribution.\n",
        "If the results of a Kruskal-Wallis test are statistically significant, then it’s appropriate to conduct Dunn’s Test to determine exactly which groups are different. <br>\n",
        "Example: https://www.statology.org/dunns-test/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "MFd0D9XQb3Ru",
        "outputId": "ed9a7f77-0f18-4b55-af61-a62db7ce2d92"
      },
      "outputs": [],
      "source": [
        "first_epoch_population = transpose_list[0]\n",
        "second_epoch_population = transpose_list[1]\n",
        "last_epoch_population = transpose_list[99]\n",
        "\n",
        "# Perform Kruskal-Wallis Test\n",
        "print(stats.kruskal(first_epoch_population, second_epoch_population, last_epoch_population))\n",
        "\n",
        "\n",
        "# Perform Dunn test\n",
        "sp.posthoc_dunn([first_epoch_population, second_epoch_population, last_epoch_population], p_adjust=\"holm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Q: Which samples originate from different distributions?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Wilcoxon test is another tool to check if there are significant differences between samples. Wilcoxon test can be used only for two groups."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform Wilcoxon Test\n",
        "print(stats.wilcoxon(first_epoch_population, second_epoch_population))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeZQuziqeMge"
      },
      "source": [
        "### TODO:\n",
        "#### Exercise 1.\n",
        "Simulate tossing a coin for:\n",
        "- fair coin (probability 50/50)\n",
        "- unfair coin (e.g. 20/80)\n",
        "- unfair coin (e.g. 90/10)\n",
        "- another two unfair coin quite close to one of the previous ones (e.g. 51/49 and 24/76).\n",
        "\n",
        "\n",
        "Please run the experiments for the coin tossers (`number_of_trials=30` ,`number_of_tosses=10`) and draw box and whisker plots to compare samples from different coins.\n",
        "Apply the relevant statistical hypotheses testing tools for checking whether the cumulative distribution functions of the samples coming from the experiments are different or not (Kruskal-Wallis + Dunn). Assume first the p-value and comment how you can interprete the result.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Exercise 2.\n",
        "Investigate source code of `scipy.stats.kruskal`. What are the differences between the implementation from `scipy` and our custom implementation?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Exercise 3.\n",
        "What are the differences between Wilcoxon and Kruskal-Wallis tests?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Exercise 4. \n",
        "Run `LocalSearch` with another mutation https://jmetal.github.io/jMetalPy/api/operator/mutation.html. Compare results. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
