{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 1 - Hypotheses Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Required dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First let us install what is needed - jmetalpy, scikit-posthocs and plotly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install jmetalpy\n",
        "%pip install scikit-posthocs\n",
        "%pip install plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import scikit_posthocs as sp\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from jmetal.core.observer import Observer\n",
        "import logging\n",
        "from jmetal.problem.singleobjective.unconstrained import Sphere\n",
        "from jmetal.core.solution import FloatSolution\n",
        "from jmetal.algorithm.singleobjective.local_search import LocalSearch\n",
        "from jmetal.operator import SimpleRandomMutation\n",
        "from jmetal.util.termination_criterion import StoppingByEvaluations\n",
        "\n",
        "pd.options.plotting.backend = \"plotly\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hypotheses Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Basic example - tossing a coin."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "HEADS = 0\n",
        "TAILS = 1\n",
        "\n",
        "COIN_VALUES = [HEADS, TAILS]\n",
        "\n",
        "\n",
        "def get_coin_tosses(number_of_tosses: int, probabilities: list[int] = [0.5, 0.5]) -> np.ndarray:\n",
        "    return np.random.choice(COIN_VALUES, size=number_of_tosses, replace=True, p=probabilities)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Estimate the probability of TAILS (calculate the proportion of those tosses that resulted in TAILS):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "coin_tosses = get_coin_tosses(number_of_tosses=10000, probabilities=[0.5, 0.5])\n",
        "probability_of_tails = None # TODO: Calculate the probability of tails"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Implement a function to `run_experiment`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_experiment(\n",
        "    number_of_trials: int, number_of_tosses: int, probabilities: list[int] = [0.5, 0.5]\n",
        ") -> list[float] | np.ndarray:\n",
        "    \"\"\"\n",
        "    Simulates a coin-tossing experiment across multiple trials and returns the estimated \n",
        "    probability of getting tails in each trial.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    number_of_trials : int\n",
        "        The number of independent trials to run. Each trial consists of multiple coin tosses.\n",
        "    \n",
        "    number_of_tosses : int\n",
        "        The number of coin tosses to perform in each trial.\n",
        "    \n",
        "    probabilities : list[float], optional\n",
        "        A list representing the probabilities for the two outcomes [HEADS, TAILS]. \n",
        "        By default, this is set to [0.5, 0.5], simulating a fair coin.\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    list[float]\n",
        "        A list of floats, where each element is the proportion of tails (1) observed in \n",
        "        a single trial. The length of the list is equal to `number_of_trials`.\n",
        "\n",
        "    Description:\n",
        "    ------------\n",
        "    For each trial, the function simulates a specified number of coin tosses, with outcomes \n",
        "    determined by the given probabilities for heads and tails. It then computes the \n",
        "    probability of tails for each trial. \n",
        "    The results are returned as a list of probabilities (one per trial).\n",
        "\n",
        "    Example:\n",
        "    --------\n",
        "    >>> run_experiment(5, 1000)\n",
        "    [0.519, 0.493, 0.497, 0.514, 0.509]\n",
        "\n",
        "    This would simulate 5 trials of 1000 coin tosses each, with a fair coin, and return the \n",
        "    estimated probability of TAILS for each trial.\n",
        "    \"\"\"\n",
        "    # TODO: Implement me!\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "def plot_experiment(tails_probabilities: list[float]) -> None:\n",
        "    fig = px.histogram(tails_probabilities, histnorm='probability density')\n",
        "    fig.update_layout(\n",
        "        title=\"Distribution of TAILS probability\",\n",
        "        xaxis_title=\"TAILS probability\",\n",
        "        yaxis_title=\"Density\",\n",
        "    )\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot results of the experiment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fair_coin_tails_probabilities = run_experiment(number_of_trials=10000, number_of_tosses=1000, probabilities=[0.5, 0.5])\n",
        "plot_experiment(fair_coin_tails_probabilities)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Q: What is the shape of this distribution called? Can you explain why it takes this shape?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "biased_coin_tails_probabilities = run_experiment(number_of_trials=10000, number_of_tosses=1000, probabilities=[0.2, 0.8])\n",
        "plot_experiment(biased_coin_tails_probabilities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.DataFrame({\n",
        "    \"fair\": fair_coin_tails_probabilities,\n",
        "    \"biased\": biased_coin_tails_probabilities\n",
        "}).plot.hist(bins=100, histnorm='probability density')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Kruskal-Wallis test\n",
        "We will implement a simplified version for 2 samples. <br>\n",
        "#### Method:\n",
        "1. Rank all data from all groups together; i.e., rank the data from 1 to N ignoring group membership. Assign any tied values the average of the ranks they would have received had they not been tied.\n",
        "2. Calculate the test statistic:\n",
        "$$ H = \\frac{12}{N (N+1)}(n_1 \\cdot \\overline{r_1}^2 + n_2 \\cdot \\overline{r_2}^2) - 3(N+1) $$\n",
        "Where:\n",
        "- $n_1$ is the number of observations in $sample_1$ and $n_2$ is the number of observations in $sample_2$,\n",
        "- $N = n_1 + n_2$ is the total number of observations across all samples,\n",
        "- $\\overline{r_1}$ is the average rank of all observations in $sample_1$.\n",
        "3. Finally, the decision to reject or not the null hypothesis is made by comparing H to a critical value $H_{c}$ obtained from a table or a software for a given significance or alpha level. If  H is bigger than $H_{c}$, the null hypothesis is rejected. If possible (no ties, sample not too big) one should compare H to the critical value obtained from the exact distribution of H. Otherwise, the distribution of H can be approximated by a chi-squared distribution with 1 degree of freedom (in general $g-1$ degrees of freedom where $g$ is the number of samples). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Source: https://en.wikipedia.org/wiki/Kruskal%E2%80%93Wallis_one-way_analysis_of_variance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Q: What's the value of H if these samples come from the same distribution (are $\\textit{equal}$)?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def kruskal_wallis(sample1: np.ndarray, sample2: np.ndarray) -> tuple[float, float]:\n",
        "    # TODO: Implement me!\n",
        "    # Use rankdata function from scipy for convenience\n",
        "    all_samples = np.concatenate([sample1, sample2])\n",
        "    ranks = stats.rankdata(all_samples, method=\"min\")\n",
        "    # H = ...\n",
        "    # p_value = stats.chi2.sf(H, 1)\n",
        "    # return H, p_value\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Null and alternative hypotheses.\n",
        "The null hypothesis ($H_0$) often represents either a skeptical perspective or a claim of “no difference” to be tested.\n",
        "The alternative hypothesis ($H_A$) represents an alternative claim under consideration and is often represented by a range of possible values for the value of interest."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### P-value\n",
        "The p-value is the probability of observing data at least as favorable to the alternative hypothesis as our current dataset, if the null hypothesis were true. We typically use a summary statistic of the data, such as a difference in proportions, to help compute the p-value and evaluate the hypotheses. This summary value that is used to compute the p-value is often called the test statistic."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Source: https://openintro-ims.netlify.app/foundations-randomization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test if your implementation is correct:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample1 = np.array([1, 2, 3])\n",
        "sample2 = np.array([4, 6, 5])\n",
        "scipy_result = stats.kruskal(sample1, sample2)\n",
        "custom_result = kruskal_wallis(sample1, sample2)\n",
        "\n",
        "assert np.isclose(scipy_result.statistic, custom_result[0])\n",
        "assert np.isclose(scipy_result.pvalue, custom_result[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate a sample for a fair coin and for a biased coin. Then check if we can detect the biased coin using Kruskal-Wallis test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "number_of_trials = 1000\n",
        "number_of_tosses = 100\n",
        "fair_coin_probabilities = [0.5, 0.5]\n",
        "biased_coin_probabilities = [0.5, 0.5] \n",
        "fair_coin_means = run_experiment(\n",
        "    number_of_trials=number_of_trials, number_of_tosses=number_of_tosses, probabilities=fair_coin_probabilities\n",
        ")\n",
        "biased_coin_means = run_experiment(\n",
        "    number_of_trials=number_of_trials, number_of_tosses=number_of_tosses, probabilities=biased_coin_probabilities\n",
        ")\n",
        "kruskal_wallis(fair_coin_means, biased_coin_means)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Q: How to decide if a coin is biased using `pvalue`?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fun fact"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fair coins tend to land on the same side they started: Evidence from 350,757 flips."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Source: https://arxiv.org/abs/2310.04153"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Key takeaways:\n",
        "- statistical testing is just another tool in your toolkit,\n",
        "- we use statistical tests to check if we can reject a hypothesis - e.g. to check if samples originate from the same distribution,\n",
        "- there are many statistical tests already implemented in scipy,\n",
        "- many ML/statistical libraries provide statistical tests out of the box (e.g. `statsmodels.regression.linear_model.OLS`) - it's crucial to understand what are the p-values,\n",
        "- try to use statistical tests for your master thesis (e.g. to check if the results of one ML algorithm are better than the baseline). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## jMetalPy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbqJNRYgKhl-"
      },
      "source": [
        "During this lab we will take a look at the jMetalPy platform, run the first simple heuristic algorithm (local search) and play with different methods of visualization and testing statistical significance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "jMetalPy provides implementation for many optimization problems - right now we will focus on `Sphere`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Alt text](https://www.sfu.ca/~ssurjano/spheref.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Source: https://www.sfu.ca/~ssurjano/spheref.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`Sphere` is defined by a formula:\n",
        "$$ f(x) = \\sum_{i=1}^{d} x_i^2 $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Global Minimum:\n",
        "$ f(x^*) = 0 $, at $x^* = (0, ..., 0)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "logger = logging.getLogger('jmetal.core.algorithm')\n",
        "logger.setLevel(logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can check it for $d=2$ and $x = [1, 2]$. The result should be equal to:\n",
        "$$ f(x) = 1^2 + 2^2 = 5$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "problem = Sphere(2)\n",
        "solution = FloatSolution(problem.lower_bound, problem.upper_bound, problem.number_of_objectives())\n",
        "solution.variables = [1.0, 2.0]\n",
        "assert problem.evaluate(solution).objectives[0] == 5.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`LocalSearch` works like this:\n",
        "- start with 1 random point from domain (sampled with uniform distribution) called `solution`,\n",
        "- for each step run mutation for the `solution`,\n",
        "- if fitness value after running mutation is better than before replace `solution` with mutated `solution`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqbgBBvEK2Y0",
        "outputId": "527e7660-454d-4f65-f760-d180ff00bded"
      },
      "outputs": [],
      "source": [
        "# Problem definition and Local Search parameters:\n",
        "PROBLEM = Sphere(10)\n",
        "MAX_EVALUATIONS = 100\n",
        "MUTATION = SimpleRandomMutation(1.0 / PROBLEM.number_of_variables())\n",
        "TERMINATION_CRITERION = StoppingByEvaluations(max_evaluations=MAX_EVALUATIONS)\n",
        "\n",
        "\n",
        "algorithm = LocalSearch(\n",
        "    problem=PROBLEM,\n",
        "    mutation=MUTATION,\n",
        "    termination_criterion=StoppingByEvaluations(max_evaluations=MAX_EVALUATIONS),\n",
        ")\n",
        "algorithm.run()\n",
        "result = algorithm.result()\n",
        "\n",
        "print(\"Algorithm: \" + algorithm.get_name())\n",
        "print(\"Problem: \" + problem.name())\n",
        "print(\"Solution: \" + str(result.variables))\n",
        "print(\"Fitness:  \" + str(result.objectives[0]))\n",
        "print(\"Computing time: \" + str(algorithm.total_computing_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5BNLyBQW-uU"
      },
      "source": [
        "This is of course a heuristic algorithm, let us run it many times and show the dispersion of the outcome.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "os_wNQyJXB6-",
        "outputId": "5b6db5b8-29df-474c-dd3a-c307162314cf"
      },
      "outputs": [],
      "source": [
        "N_RUNS = 30\n",
        "results = []\n",
        "for _ in range(N_RUNS):\n",
        "    algorithm = LocalSearch(\n",
        "        problem=PROBLEM,\n",
        "        mutation=MUTATION,\n",
        "        termination_criterion=StoppingByEvaluations(max_evaluations=MAX_EVALUATIONS),\n",
        "    )\n",
        "    algorithm.run()\n",
        "    result = algorithm.result().objectives[0]\n",
        "    results.append(result)\n",
        "\n",
        "fig = px.box(results)\n",
        "fig.update_layout(\n",
        "    title=\"Fitness distribution\",\n",
        "    yaxis_title=\"Sphere function values\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISV6STZ2eL9_"
      },
      "source": [
        "It would be nice to see the progress of the algorithm. First let us take a look at a toy  - a progress bar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaK6_WBneWm0",
        "outputId": "86cf0216-742a-4fba-993b-43ac5339007b"
      },
      "outputs": [],
      "source": [
        "from jmetal.util.observer import ProgressBarObserver\n",
        "\n",
        "max_evaluations = 100000\n",
        "algorithm = LocalSearch(\n",
        "    problem=PROBLEM,\n",
        "    mutation=MUTATION,\n",
        "    termination_criterion=StoppingByEvaluations(max_evaluations=max_evaluations),\n",
        ")\n",
        "basic = ProgressBarObserver(max=max_evaluations)\n",
        "algorithm.observable.register(observer=basic)\n",
        "\n",
        "algorithm.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CkqFmxhktzb"
      },
      "source": [
        "However it would be better to take a closer look at what is happening in the algorithm - what is the value of the best fitness in every step, or at certain moments in time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "TofOOluzk0AI",
        "outputId": "a7929df5-b5ca-4a8c-f644-103c413bc28c"
      },
      "outputs": [],
      "source": [
        "class DataObserver(Observer):\n",
        "\n",
        "    def __init__(self, frequency: float = 1.0) -> None:\n",
        "        \"\"\"Show the number of evaluations, best fitness and computing time.\n",
        "        :param frequency: Display frequency.\"\"\"\n",
        "        self.display_frequency = frequency\n",
        "        self.data = []\n",
        "\n",
        "    def update(self, *args, **kwargs):\n",
        "        evaluations = kwargs[\"EVALUATIONS\"]\n",
        "        solutions = kwargs[\"SOLUTIONS\"]\n",
        "\n",
        "        if (evaluations % self.display_frequency) == 0 and solutions:\n",
        "            if type(solutions) == list:\n",
        "                fitness = solutions[0].objectives\n",
        "            else:\n",
        "                fitness = solutions.objectives\n",
        "            self.data.append(fitness[0])\n",
        "\n",
        "\n",
        "algorithm = LocalSearch(\n",
        "    problem=PROBLEM,\n",
        "    mutation=MUTATION,\n",
        "    termination_criterion=StoppingByEvaluations(max_evaluations=MAX_EVALUATIONS),\n",
        ")\n",
        "dataobserver = DataObserver(frequency=1.0)\n",
        "algorithm.observable.register(observer=dataobserver)\n",
        "\n",
        "algorithm.run()\n",
        "\n",
        "px.line(dataobserver.data).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShLMqEWPKRyH"
      },
      "source": [
        "Now let us take a proper look at the progress of the algorithm. Let us repeat it many times, and draw an appropriate box and whiskers plot for every moment in time, observing the best fitness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "Tyl7giidKYkF",
        "outputId": "965d6a37-ae26-4cae-c041-0be0435467fd"
      },
      "outputs": [],
      "source": [
        "fitness_values = []\n",
        "for _ in range(N_RUNS):\n",
        "    algorithm = LocalSearch(\n",
        "        problem=PROBLEM,\n",
        "        mutation=MUTATION,\n",
        "        termination_criterion=StoppingByEvaluations(max_evaluations=MAX_EVALUATIONS),\n",
        "    )\n",
        "    observer = DataObserver(frequency=1.0)\n",
        "    algorithm.observable.register(observer=observer)\n",
        "    algorithm.run()\n",
        "    fitness_values.append(observer.data)\n",
        "\n",
        "fitness_values = np.array(fitness_values)\n",
        "\n",
        "px.box(fitness_values).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Statistical tests\n",
        "A Kruskal-Wallis test is used for testing whether (two or more) samples originate from the same distribution.\n",
        "If the results of a Kruskal-Wallis test are statistically significant, then it’s appropriate to conduct Dunn’s Test to determine exactly which groups are different. <br>\n",
        "Example: https://www.statology.org/dunns-test/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "MFd0D9XQb3Ru",
        "outputId": "ed9a7f77-0f18-4b55-af61-a62db7ce2d92"
      },
      "outputs": [],
      "source": [
        "first_epoch_population = fitness_values[:, 0]\n",
        "second_epoch_population = fitness_values[:, 1]\n",
        "last_epoch_population = fitness_values[:, 99]\n",
        "\n",
        "# Perform Kruskal-Wallis Test\n",
        "print(stats.kruskal(first_epoch_population, second_epoch_population, last_epoch_population))\n",
        "\n",
        "\n",
        "# Perform Dunn test\n",
        "sp.posthoc_dunn([first_epoch_population, second_epoch_population, last_epoch_population], p_adjust=\"holm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Q: Which samples originate from different distributions?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Wilcoxon test is another tool to check if there are significant differences between samples. Wilcoxon test can be used only for two groups."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform Wilcoxon Test\n",
        "print(stats.wilcoxon(first_epoch_population, second_epoch_population))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeZQuziqeMge"
      },
      "source": [
        "### TODO:\n",
        "#### Exercise 1.\n",
        "Simulate coin tosses for the following scenarios:\n",
        "- Fair coin (50/50 probability),\n",
        "- Unfair coin (e.g., 20/80 probability),\n",
        "- Unfair coin (e.g., 90/10 probability),\n",
        "- Two additional unfair coins with probabilities close to those of the previous examples (e.g., 51/49 and 24/76).\n",
        "\n",
        "Instructions:\n",
        "- Conduct the simulations for the coin tosses using the following parameters:\n",
        "```\n",
        "number_of_trials = 30\n",
        "number_of_tosses = 10\n",
        "```\n",
        "- Generate box-and-whisker plots to visually compare the results for each coin's sample distribution.\n",
        "- Apply appropriate statistical hypothesis tests to determine whether the cumulative distribution functions (CDFs) of the samples from different coins are significantly different. Use the Kruskal-Wallis test followed by Dunn's post hoc test for pairwise comparisons.\n",
        "- Assume an initial p-value and interpret the results. Provide comments on how to understand the statistical significance of the differences between the coin distributions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Exercise 2.\n",
        "Investigate source code of `scipy.stats.kruskal`. What are the differences between the implementation from `scipy` and our custom implementation?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Exercise 3.\n",
        "What are the differences between Wilcoxon and Kruskal-Wallis tests?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Exercise 4. \n",
        "Run `LocalSearch` with another mutation https://jmetal.github.io/jMetalPy/api/operator/mutation.html. Use tests to check if the results are statistically different."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
